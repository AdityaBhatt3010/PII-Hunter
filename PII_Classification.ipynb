{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdityaBhatt3010/PII_Tryy/blob/main/PII_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "3_b2AWoS2H0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fc25fb-85fb-404f-cd9e-502444cfa742"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "IyrgGuW4DlOX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "model_name = \"iiiorg/piiranha-v1-detect-personal-information\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "def annotate_pii(text):\n",
        "    # Tokenize with offsets\n",
        "    encoded_inputs = tokenizer(text, return_offsets_mapping=True, return_tensors=\"pt\", truncation=True)\n",
        "    offset_mapping = encoded_inputs.pop(\"offset_mapping\")[0].tolist()\n",
        "    encoded_inputs = {k: v.to(device) for k, v in encoded_inputs.items()}\n",
        "\n",
        "    # Get predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded_inputs)\n",
        "    predictions = torch.argmax(outputs.logits, dim=-1)[0].tolist()\n",
        "\n",
        "    # Reconstruct the annotated text\n",
        "    spans = []\n",
        "    current_entity = None\n",
        "    current_text = \"\"\n",
        "    current_start = 0\n",
        "\n",
        "    for i, (start, end) in enumerate(offset_mapping):\n",
        "        if start == end:\n",
        "            continue  # Skip special tokens\n",
        "\n",
        "        label_id = predictions[i]\n",
        "        label = model.config.id2label[label_id]\n",
        "\n",
        "        if label != \"O\":\n",
        "            if current_entity is None:\n",
        "                current_entity = label\n",
        "                current_text = text[start:end]\n",
        "                current_start = start\n",
        "            elif label == current_entity:\n",
        "                current_text += text[start:end]\n",
        "            else:\n",
        "                spans.append((current_start, current_text, current_entity))\n",
        "                current_entity = label\n",
        "                current_text = text[start:end]\n",
        "                current_start = start\n",
        "        else:\n",
        "            if current_entity:\n",
        "                spans.append((current_start, current_text, current_entity))\n",
        "                current_entity = None\n",
        "                current_text = \"\"\n",
        "\n",
        "    if current_entity:\n",
        "        spans.append((current_start, current_text, current_entity))\n",
        "\n",
        "    # Build the final annotated string\n",
        "    annotated_text = \"\"\n",
        "    last_index = 0\n",
        "    for start, value, entity in sorted(spans):\n",
        "        annotated_text += text[last_index:start]\n",
        "        annotated_text += f\"[{value} | {entity}]\"\n",
        "        last_index = start + len(value)\n",
        "\n",
        "    annotated_text += text[last_index:]\n",
        "    return annotated_text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "example_text = \"Yesterday, Aditya scheduled a team meeting at 9:00 AM to discuss the quarterly marketing strategies. She sent out invitations from her email emily.watson93@example.com and confirmed attendance over the phone at (415) 992-5587. The meeting was held at their San Francisco office, located at 220 Market Street, Suite 804, San Francisco, CA 94105. During the session, Daniel Lee mentioned integrating analytics from the new customer database, which is currently stored under Project Orion. Later in the day, Emily's package was delivered and signed for using her ID number A1234567, as registered under the California DMV. Meanwhile, the finance department cross-verified employee records using their SSNs, like 521-47-8912, and banking details such as Bank of America Account No. 004567891234. The internal Slack message also included a link to a private GitHub repo and a backup contact email: dlee.corp@protonmail.com.\"\n",
        "\n",
        "print(\"Annotated PII Output:\\n\")\n",
        "print(annotate_pii(example_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2A1X1hi9BMi",
        "outputId": "76daf783-2e30-43f2-f115-327ebaace75d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Annotated PII Output:\n",
            "\n",
            "Yesterday,[ Aditya | I-GIVENNAME] scheduled a team meeting at 9:00 AM to discuss the quarterly marketing strategies. She sent out invitations from her email[ emily.watson93@ | I-EMAIL]example.com and confirmed attendance over the phone at[ (415) 992-5587 | I-TELEPHONENUM]. The meeting was held at their[ San Francisco | I-CITY] office, located at[ 220 | I-BUILDINGNUM][ Market Street | I-STREET], Suite 804,[ San Francisco | I-CITY], CA[ 94105. | I-ZIPCODE] During the session, Daniel Lee mentioned integrating analytics from the new customer database, which is currently stored under Project Orion. Later in the day, Emily's package was delivered and signed for using her ID number[ A1234567 | I-IDCARDNUM], as registered under the California DMV. Meanwhile, the finance department cross-verified employee records using their SSNs, like[ 521-47-8912 | I-SOCIALNUM], and banking details such as Bank of America Account No.[ 004567891234 | I-ACCOUNTNUM]. The internal Slack message also included a link to a private GitHub repo and a backup contact email:[ dlee.corp@protonmail.com | I-EMAIL].\n"
          ]
        }
      ]
    }
  ]
}